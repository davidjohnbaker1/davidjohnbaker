---
title: "hire-me-ds-3"
author: "David John Baker"
date: "January 16, 2018"
output: html_document
---

```{r}
library(ggplot2)
library(data.table)
beer <- fread("../content/post/data/beer_reviews.csv") 
```

Two questions down, two to go!
For the third post in this series, I'll explore the question:

> Which of the factors (aroma, taste, appearance, palette) are most important in determining the overall quality of a beer?

Whereas the posts before were questions of sorting data, this is our first attempt to make some statistical models.
In this case we're going to be doing a bit of regression modeling. 

Now there are a ton of ways to tackle this problem.
We could run some basic linear regression models and spent the whole post talking beta coeffecients and what assumptions we violated.
We could do a linear mixed effects model, then realize that doing so would be a terrible choice (I tried it for the fun of it, bad idea).
Or we do some fun non-parametric, machine learning models that are on the easier-to-interpret side. 
Since ML is so hot right now, let's stick with that. 

## Machine Learning and Non-Parametric Models 

In machine learning, non-parametric models are the ones that make no assumptions about the data.
The models do not assume that our points come from beautiful, normally distributed ideal poplulations; they just seek to find some sort of way to give us a good rule of thumb about our data.

In this case we need to make a model to predict the quality of beer (our dependent variable, ```review_overall```) based on four different independent variables (```review_aroma```, ```review_taste```, ```review_appearance```, ```review_palete```).

My friend Tabi, the data scientist over at Soundout suggested that an easy way to tackle this problem would be try a Random Forrest Model.
Some great explanations about how these models work can be found here(titanic) and here (ISLR), and here(BEN) since this isn't a post about how random forest models work, but basically the idea is an algorithm is goint to go through your dataset and find key variables that help you split it up.
Relevant to our question, the degree to which the algorithm splits our dataset is going to help us figure out what are the important variables. 

Before running this model though, we need to talk about a small depence problem in our dataset.
In my earlier post I talked about how we probably should not just run a model on the data _as is_.
Last time we found there were tons of NAs in our dataset, that not all beers were equally represented, and that not all reviewers were making even amonts of reviews.
In addition to these problems, there is also the problem that some reviewers might rate generally higher or lower _all the time_.
Since we know things like this exist, we want to account for them. 

There are a few ways to do this, but the way I think is best to get around it is to only look at ratings of unique beers that have over 30 ratings (as we did before).
This way we know each rating for each unique beer is indpendent (we assume no one is rating the same beer over and over again).
Once we have that we can then take an average of each beer (we'll have unequal numbers, but I'm OK with that) and use that in our model. 
Let's index out the data we need!

```{r}
# Make READABLE unique beer ID
beer[, beer_name_unique := paste(brewery_name,beer_name, beer_style)]

# Only beers with over 30 reviews 
reliable.beers <- beer[, .(ReviewsBeerHas = .N), by = beer_name_unique][order(-ReviewsBeerHas)][ReviewsBeerHas > 30]

# Merge with Inner Join 
beer.reliable <- reliable.beers[beer, on = "beer_name_unique", nomatch=0]

# Make indepent ratings 
prediction.data <- beer.reliable[, .(AvgOverall = mean(review_overall),
         AvgAroma = mean(review_aroma),
         AvgTaste = mean(review_taste),
         AvgApp = mean(review_appearance),
         AvgPal = mean(review_palate)), by = beer_name_unique]
```


Now that we have some better data, let's fit a random forest model attempting to predict the average overall rating from our four others.
We'll use the randomForest package and make sure to ask it to include a measure of importance. 

```{r}
library(randomForest)
set.seed(666)
random.forrest.fit <- randomForest(AvgOverall ~ AvgAroma + AvgTaste + AvgApp + AvgPal, data = prediction.data, importance = TRUE)
random.forrest.fit$importance
```

The randomForest object gives us two different measures. 
The first one, ```%IncMSE``` is a measure that tells us how much our model's MSE or Mean Square Error would change if we were to take that out of our model.
Average taste here is trouncing the other variables in terms of importance. 
The second variable, ```IncNodePurity``` gives us a measure of node purity from all of the trees that were used in creating our model. 
Here Taste again leads in terms of importance, but our Pallete variable seems to be close behind.
We see this visually below.

```{r}
varImpPlot(random.forrest.fit, main = "Variable Importance Metrics")
```


The result that Taste seems to be taking the cake here is to be expected.
Using some of the more basic tools of statistics and data science if we look at the correlation between our taste variable and our overall it's quite high.
Actually looking at our average ratings, all the correlations are really high! 

```{r}
cor(prediction.data[,-1])
```

Doing the analysis like this presents some strange issues of collinearity.
Having an _r_ = .951 for our Overall and Taste variables is obnoxiously high.
An _r_ = .974 for Palate and Taste is also strangely large. 
If you coming from more of a psychology background you would almost never see correlations this high in the wild. 

They go down a bit if you end up looking at the non-aggregated sets too (see below), but again remember that these values have that dependence and outier issues with them.
Still, taste and overall are the highest correlated variables.

```{r}
cor(beer[, .(review_overall,review_aroma,review_appearance,review_palate,review_taste)])
```

This effect is probably due to the fact that higher beers tend to just score higher on everything. 
It would be pretty strange in pratcice to give a beer a 5/5 overall but then think it's deserving of a 2 in Taste.
If I were on a team at Beer Advocate I might try to suggest maybe incorporating either a larger range of ratings or maybe thinking about different dimensions to ask people to rate like maybe hoppiness or bang-for-your-buck; variables that will lead to having less collinearity issues. 

So the take-home here is that the taste variable is the most important variable for determining the overall rating!