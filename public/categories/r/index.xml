<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on David John Baker</title>
    <link>/categories/r/</link>
    <description>Recent content in R on David John Baker</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 David John Baker</copyright>
    <lastBuildDate>Sat, 13 Jan 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/r/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Hire Me (as a Data Scientist!), Part I</title>
      <link>/post/hire-me-as-a-data-scientist-part-i/</link>
      <pubDate>Sat, 13 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/hire-me-as-a-data-scientist-part-i/</guid>
      <description>&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;I read &lt;a href=&#34;https://medium.com/&#34;&gt;Medium&lt;/a&gt; blogs posts on “How to Become a Data Scientist” more often than I care to admit. Much of this comes from a fear that after doing all this work in the PhD and then hitting the Music Theory job market that I won’t fit the mold of the kind of theorist most schools want to hire. Not coming from &lt;a href=&#34;https://pushpullfork.com/music-theory-job-market/&#34;&gt;one of five schools that seem to have a monopoly on the tenure track jobs&lt;/a&gt; can be a bit discouraging, but I also won’t deny that having regular 9-5 with a &lt;a href=&#34;https://www.glassdoor.com/Salaries/data-scientist-salary-SRCH_KO0,14.htm&#34;&gt;decent salary&lt;/a&gt; is pretty tempting after spending the vast majority of my twenties in school. And even if I don’t go on over to the darkside after the PhD, I’ll probably always be looking for a bit more work in summers.&lt;/p&gt;
&lt;p&gt;On top of all of that, I believe that skills that acquired in a PhD (especially if you do computational musicology and music cognition!) are very transferable to most jobs and it’s just a matter of being a bit more pro-active in promoting yourself that might help me one day land a stable, non-academic job.&lt;/p&gt;
&lt;p&gt;That said, one tweet that I saw last week by &lt;a href=&#34;https://twitter.com/kierisi&#34;&gt;Jesse Meagan&lt;/a&gt; linked to this really interesting Linked-In post by &lt;a href=&#34;https://twitter.com/tanyacash21&#34;&gt;Tanya Cashorali&lt;/a&gt; that proported to have a &lt;a href=&#34;https://www.linkedin.com/pulse/how-hire-test-data-skills-one-size-fits-all-interview-tanya-cashorali/&#34;&gt;one size fits all data-science interview process&lt;/a&gt; which has candidates take home a big dataset with a bunch of beer reviews and answer four very broad questions. Considering myself an afficiando of How-To-Become-a-Data Scientist articles, this of course caught my eye.&lt;/p&gt;
&lt;p&gt;After reading the article I figured why not give it a go? It’s the start of the semester, I’m basically ABD, need more of a portfolio beyond &lt;a href=&#34;www.github.com/davidjohnbaker1&#34;&gt;my github&lt;/a&gt;, and I have nothing to do with my Saturday morning. So why not see what I can produce in 4 or 5 hours? At the very least I’ll hopefully just have something to point to if a future employer wants to see how I think through data-science problems.&lt;/p&gt;
&lt;p&gt;And if anyone is reading this that does have comments on my code or thought process… please let me know what you think on &lt;a href=&#34;www.twitter.com/DavidJohnBaker&#34;&gt;Twitter&lt;/a&gt;! I’d love some feedback!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring the Dataset&lt;/h2&gt;
&lt;p&gt;The first thing I did was to grab this dataset which you can get &lt;a href=&#34;https://s3.amazonaws.com/demo-datasets/beer_reviews.tar.gz?lipi=urn%3Ali%3Apage%3Ad_flagship3_pulse_read%3BDqDjqRycTlq5seB4xN3ocA%3D%3D&#34;&gt;here&lt;/a&gt; and then I set up my R script with a few of my favorite packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#=====================================================================================#
# Beer Script
#=====================================================================================#
# Library
library(ggplot2)
library(data.table)
library(stringr)
#=====================================================================================#
beer &amp;lt;- fread(&amp;quot;data/beer_reviews.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
Read 81.9% of 1586614 rows
Read 1586614 rows and 13 (of 13) columns from 0.168 GB file in 00:00:03&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#=====================================================================================#&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset has about 1.5 million observations across 14 different observations, so don’t try to open it in LibreOffice. The reviews come from a variety of different users that have rated the beers based on five different attributes (Appearance, Pallete, Aroma, Taste, Overall) and then each beer has a few other variables listed such as its ABV, the brewery it comes from, the beer’s name (duh), and what kind of beer it is.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(beer)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;brewery_id&amp;quot;         &amp;quot;brewery_name&amp;quot;       &amp;quot;review_time&amp;quot;       
##  [4] &amp;quot;review_overall&amp;quot;     &amp;quot;review_aroma&amp;quot;       &amp;quot;review_appearance&amp;quot; 
##  [7] &amp;quot;review_profilename&amp;quot; &amp;quot;beer_style&amp;quot;         &amp;quot;review_palate&amp;quot;     
## [10] &amp;quot;review_taste&amp;quot;       &amp;quot;beer_name&amp;quot;          &amp;quot;beer_abv&amp;quot;          
## [13] &amp;quot;beer_beerid&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer[, .(.N = unique(beer$brewery_name))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                 .N
##    1:              Vecchio Birraio
##    2:      Caldera Brewing Company
##    3:       Amstel Brouwerij B. V.
##    4:        Broad Ripple Brew Pub
##    5:   Moon River Brewing Company
##   ---                             
## 5739:        Gattopardo Cervejaria
## 5740:         Brauerei Lasser GmbH
## 5741:        Wissey Valley Brewery
## 5742:      Outback Brewery Pty Ltd
## 5743: Georg Meinel Bierbrauerei KG&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer[, .(.N = unique(beer$review_profilename))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    .N
##     1:        stcules
##     2: johnmichaelsen
##     3:        oline73
##     4:      Reidrover
##     5:   alpinebryant
##    ---               
## 33384:     jennaizzel
## 33385:    mine2design
## 33386:       hogshead
## 33387:     NyackNicky
## 33388:        joeebbs&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer[, .(.N = unique(beer$beer_name))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            .N
##     1:           Sausa Weizen
##     2:               Red Moon
##     3: Black Horse Black Beer
##     4:             Sausa Pils
##     5:          Cauldron DIPA
##    ---                       
## 56853:      Bear Mountain Ale
## 56854:        Highland Porter
## 56855:       Baron Von Weizen
## 56856:          Resolution #2
## 56857:     The Horseman&amp;#39;s Ale&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer[, .(.N = unique(beer$beer_style))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                   .N
##   1:                      Hefeweizen
##   2:              English Strong Ale
##   3:          Foreign / Export Stout
##   4:                 German Pilsener
##   5:  American Double / Imperial IPA
##  ---                                
## 100:                          Gueuze
## 101:                            Gose
## 102:                        Happoshu
## 103:                           Sahti
## 104: Bière de Champagne / Bière Brut&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From a bird’s eye view we have 56,857 unique beers in 104 different categories from 5,743 different breweries and 33,388 unique beer afficianados who have gone out of their way to tell this website what they think about the beers they drink.&lt;/p&gt;
&lt;p&gt;Before diving in further, it’s worth doing a prelimnary check of the quality of the data (aka we should know if this is BAD (Best Availible Data) or has undergone a fair deal of cleaning). As someone who comes from a more psychology background, I’ve noticed what certain people consider “clean” when it comes to data is quite variable.&lt;/p&gt;
&lt;p&gt;The first thing I check for is if there is any kind of data missing and if there is, is it due to chance? Or is it due to some sort of systematic variation?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(complete.cases(beer))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   FALSE    TRUE 
##   67785 1518829&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;67785/1518829&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04462978&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So about 4% of our rows don’t have every entry, so probably not too much cause for concern unless we start getting into specific questions about specific beers. Looking into this a bit further it seems like it’s just beers missing the ABV of the beer. Anyone that has made some beer ratings has made ratings on all five variables. And although it’s only 4% of our entire ratings that don’t have their ABV, comparing that to every beer we have, we see we are actually missing ~25% of the ABV ratings of all of our beers. That could be a problem later, but it’s good to know about it sooner rather than later.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer.complete &amp;lt;- beer[complete.cases(beer)]

beer[!complete.cases(beer)][, .(.N = unique(beer_name))]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                             .N
##     1: Cauldron Espresso Stout
##     2:    The Highland Stagger
##     3:              Alpha Beta
##     4:          Imperial Stout
##     5:               Megalodon
##    ---                        
## 14106:       English Nut Brown
## 14107:              Hop Common
## 14108:     Very Hoppy Pale Ale
## 14109:       Prohibition Lager
## 14110:           Resolution #2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;14110/56857&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2481665&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beer[969]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    brewery_id             brewery_name review_time review_overall
## 1:      12770 City Grille and Brewhaus  1145738954              4
##    review_aroma review_appearance review_profilename
## 1:            3                 4         UncleJimbo
##                 beer_style review_palate review_taste     beer_name
## 1: American Pale Ale (APA)           3.5            4 City Pale Ale
##    beer_abv beer_beerid
## 1:       NA       30088&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More problems might come up here or there, but let’s move on the the first question.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;which-brewery-produces-the-strongest-beers-by-abv&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Which brewery produces the strongest beers by ABV%?&lt;/h2&gt;
&lt;p&gt;Answering the first question on the list is pretty straight forward. Essentially all you need to do is grab all of the observations that have an ABV associated with their rating, then get the average ABV of all the beers that that brewery produces.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Use object before that has only ratings with ABVs 
beer.complete[, .(AvgABV = mean(beer_abv)), by = brewery_name]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       brewery_name   AvgABV
##    1:              Vecchio Birraio 5.675000
##    2:      Caldera Brewing Company 6.168849
##    3:       Amstel Brouwerij B. V. 3.816373
##    4:        Broad Ripple Brew Pub 6.006202
##    5:   Moon River Brewing Company 5.724103
##   ---                                      
## 5152:        Gattopardo Cervejaria 6.033333
## 5153:         Brauerei Lasser GmbH 5.200000
## 5154:        Wissey Valley Brewery 5.133333
## 5155:      Outback Brewery Pty Ltd 4.787879
## 5156: Georg Meinel Bierbrauerei KG 5.850000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create table that has means and standard deviations of beers by brewery 
# Order them from most to least
abv.counter &amp;lt;- beer.complete[, .(AvgABV = mean(beer_abv), 
                                 SdABV = sd(beer_abv)) , 
                             by = brewery_name][order(-AvgABV)]
abv.counter&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              brewery_name     AvgABV      SdABV
##    1:                        Schorschbräu 19.2288235 12.3273042
##    2:                       Shoes Brewery 15.2000000  0.0000000
##    3:                Rome Brewing Company 13.8400000  1.9718012
##    4:                   Hurlimann Brewery 13.7500000  0.5752237
##    5:            Alt-Oberurseler Brauhaus 13.2000000         NA
##   ---                                                          
## 5152:             Cerveceria Vegana, S.A.  2.2608696  2.2455490
## 5153: Moskovskaya Pivovarennaya Kompaniya  2.1500000  1.6881943
## 5154:                      Fentimans Ltd.  1.3750000  1.6201852
## 5155:                        Borodino ZAO  0.9666667  0.4041452
## 5156:                    All Stars Bakery  0.5000000  0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Having this table could be good enough for government work, but looking at the output there are clearly problems and one thing to consider in this table (and pretty much this whole dataset) is “Is this data point a good representation of what I am trying to measure?”. Note for example the huge variability as measured by the standard deviation in our top answer as well as the fact that some of the SDs have NAs and there is a value of 0. Given that, I think it’d be good to put on some sort of threshold that would up the quality of our answers. One way to do this would be to see exactly how many beers each brewery makes and use that as a proxy for how big the brewery is.&lt;/p&gt;
&lt;p&gt;The code below does just that and reveals the variability in terms of size of breweries within this dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create table that counts number of beers 
NoOfBeers &amp;lt;- beer.complete[, .(NameOfBeer = unique(beer_name)), 
                           by = brewery_name][, .(.N), by = brewery_name]
NoOfBeers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       brewery_name  N
##    1:              Vecchio Birraio  4
##    2:      Caldera Brewing Company 25
##    3:       Amstel Brouwerij B. V.  9
##    4:        Broad Ripple Brew Pub 40
##    5:   Moon River Brewing Company 34
##   ---                                
## 5152:        Gattopardo Cervejaria  3
## 5153:         Brauerei Lasser GmbH  1
## 5154:        Wissey Valley Brewery  3
## 5155:      Outback Brewery Pty Ltd  6
## 5156: Georg Meinel Bierbrauerei KG  2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make table that lists each beer with it&amp;#39;s ABV and the name of the brewery
abv.table &amp;lt;- NoOfBeers[abv.counter, on = &amp;quot;brewery_name&amp;quot;]
abv.table&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                              brewery_name  N     AvgABV      SdABV
##    1:                        Schorschbräu 10 19.2288235 12.3273042
##    2:                       Shoes Brewery  1 15.2000000  0.0000000
##    3:                Rome Brewing Company  2 13.8400000  1.9718012
##    4:                   Hurlimann Brewery  3 13.7500000  0.5752237
##    5:            Alt-Oberurseler Brauhaus  1 13.2000000         NA
##   ---                                                             
## 5152:             Cerveceria Vegana, S.A.  2  2.2608696  2.2455490
## 5153: Moskovskaya Pivovarennaya Kompaniya  2  2.1500000  1.6881943
## 5154:                      Fentimans Ltd.  3  1.3750000  1.6201852
## 5155:                        Borodino ZAO  2  0.9666667  0.4041452
## 5156:                    All Stars Bakery  1  0.5000000  0.0000000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create z scores 
abv.table[, zAvgABV := scale(AvgABV)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After visually inspecting the graph on the size of breweries (below), I figured I could just look at breweries that make over five beers (which hopefully wipes out your hipster friend’s “micro brewery” in his basement where he is just trying to make the most potent IPA ever) and then only look at beers that score 4 standard deviations above the mean of all beers in terms of ABV content to narrow down possible.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# How many beers to count for a big brewery? 
hist(NoOfBeers$N, breaks= 20, 
     main = &amp;quot;Distribution of Size of Breweries&amp;quot;, 
     xlab = &amp;quot;Number of Beers Produced by a Brewery&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-14-hire-me-as-a-data-scientist-part-i_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NoOfBeers[N &amp;gt; 200] # Clearly some big breweries here! &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                        brewery_name   N
## 1:    Minneapolis Town Hall Brewery 243
## 2:            Goose Island Beer Co. 304
## 3:   Iron Hill Brewery &amp;amp; Restaurant 269
## 4: Rock Bottom Restaurant &amp;amp; Brewery 522&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abv.table[N &amp;gt;= 5, ][order(-AvgABV)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                              brewery_name   N    AvgABV
##    1:                                        Schorschbräu  10 19.228824
##    2: Brasserie Grain d&amp;#39; Orge (Brasserie Jeanne d&amp;#39;Arc SA)  10 12.445860
##    3:                          Brauerei Schloss Eggenberg  14 11.779681
##    4:                     Brasserie Dubuisson Frères sprl  14 11.432746
##    5:                            Kuhnhenn Brewing Company 142 11.345839
##   ---                                                                  
## 2539:                             Berliner Kindl Brauerei  12  3.532627
## 2540:  Yanjing Pijiu (Guilin Liquan) Gufen Youxian Gongsi   5  3.440000
## 2541:                                            Ochakovo  16  3.203150
## 2542:                        Grogg&amp;#39;s Pinnacle Brewing Co.   6  3.200000
## 2543:                                        Deka Brewery   7  2.620000
##            SdABV   zAvgABV
##    1: 12.3273042 10.235332
##    2:  1.7054879  5.048898
##    3:  3.0759353  4.539520
##    4:  1.6583471  4.274244
##    5:  3.5788003  4.207793
##   ---                     
## 2539:  1.0372607 -1.766396
## 2540:  0.6426508 -1.837221
## 2541:  1.2735986 -2.018323
## 2542:  0.0000000 -2.020731
## 2543:  1.6356553 -2.464215&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(abv.table[N &amp;gt;= 5, ][order(-AvgABV)]$zAvgABV,
     xlab = &amp;quot;z Score of ABV&amp;quot;, 
     main = &amp;quot;Distribution of ABV in Breweries that make more than 5 Beers&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-14-hire-me-as-a-data-scientist-part-i_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;abv.table[N &amp;gt;= 5 &amp;amp; zAvgABV &amp;gt; 4, ][order(-AvgABV)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                                           brewery_name   N   AvgABV
## 1:                                        Schorschbräu  10 19.22882
## 2: Brasserie Grain d&amp;#39; Orge (Brasserie Jeanne d&amp;#39;Arc SA)  10 12.44586
## 3:                          Brauerei Schloss Eggenberg  14 11.77968
## 4:                     Brasserie Dubuisson Frères sprl  14 11.43275
## 5:                            Kuhnhenn Brewing Company 142 11.34584
##        SdABV   zAvgABV
## 1: 12.327304 10.235332
## 2:  1.705488  5.048898
## 3:  3.075935  4.539520
## 4:  1.658347  4.274244
## 5:  3.578800  4.207793&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Doing it this way puts Schorschbräu as the highest ABV brewery, which makes sense because &lt;a href=&#34;https://www.beeradvocate.com/beer/profile/6513/51466/?ba=wordemupg&#34;&gt;they claim to make the world’s strongest beer&lt;/a&gt;. Making a quick plot of the data for our winner and the second place finisher, we see how strong Schorschbräu really is.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;schor.abv &amp;lt;- beer.complete[brewery_name == &amp;quot;Schorschbräu&amp;quot;, 
                           .(beer_name = unique(beer_name)), by = beer_abv]

ggplot(schor.abv, aes(x = beer_name, y = beer_abv)) + 
  geom_bar(stat = &amp;quot;identity&amp;quot;)  + 
  labs( title = &amp;quot;Schorschbräu Beer ABV&amp;quot;, x = &amp;quot;Beer Name&amp;quot;, y = &amp;quot;ABV&amp;quot;) +
   theme(axis.text.x=element_text(angle = -90, hjust = 0)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-14-hire-me-as-a-data-scientist-part-i_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;brassOrg.abv &amp;lt;- beer.complete[brewery_name == &amp;quot;Brasserie Grain d&amp;#39; Orge (Brasserie Jeanne d&amp;#39;Arc SA)&amp;quot;, 
                              .(beer_name = unique(beer_name)), by = beer_abv]

ggplot(brassOrg.abv, aes(x = beer_name, y = beer_abv)) + 
  geom_bar(stat = &amp;quot;identity&amp;quot;)  + 
  labs( title = &amp;quot;Brasserie Grain d&amp;#39; Orge Beer ABV&amp;quot;, 
        x = &amp;quot;Beer Name&amp;quot;, 
        y = &amp;quot;ABV&amp;quot;) +
   theme(axis.text.x=element_text(angle = -90, hjust = 0)) + ylim(0, 60) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-14-hire-me-as-a-data-scientist-part-i_files/figure-html/unnamed-chunk-8-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As I try to keep my posts on this site short and sweet, let’s move to Part II for answering Question 2!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Looking For Musicologists on Twitter</title>
      <link>/post/looking-for-musicologists-on-twitter/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/looking-for-musicologists-on-twitter/</guid>
      <description>&lt;p&gt;For the most part, Twitter is full of garbage. But I’m an optimist and a firm believer in &lt;a href=&#34;https://en.wikipedia.org/wiki/Sturgeon%27s_law&#34;&gt;Sturgeon’s Law&lt;/a&gt; so by that logic there must be some good on it. That good is academic twitter.&lt;/p&gt;
&lt;p&gt;While this isn’t a post advocating for academic Twitter, I did want to&lt;br /&gt;
1. see if I could figure out how to write a post with some R code in it and 2. share how I scraped Twitter to find active users in the Musicology and Music Theory community&lt;/p&gt;
&lt;p&gt;So here it goes…&lt;/p&gt;
&lt;p&gt;The first thing that you have to do is get some tweets. Luckily some packages exist in the #rstats world that can help with this. For this project I used the &lt;a href=&#34;https://cran.r-project.org/web/packages/twitteR/twitteR.pdf&#34;&gt;twitteR&lt;/a&gt; package which lets you log into Twitter’s API via R and and search it. There are already some instructions on how to get started with it that you can find &lt;a href=&#34;https://davetang.org/muse/2013/04/06/using-the-r_twitter-package/&#34;&gt;here&lt;/a&gt;, so I won’t go into tons of detail about setting it up. (Also please note you can’t just copy and paste my code verbatim since it requires credentials from &lt;em&gt;your&lt;/em&gt; own Twitter account)&lt;/p&gt;
&lt;p&gt;Let’s first load the two packages we’ll need.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(twitteR)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next up, we need to access Twitter’s API by entering in the details from the link above. I find it’s easiest to copy and paste each of my keys and tokens into a nice little character string, assign those to an object, then call those objects in the last command in this block.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;consumer_key &amp;lt;- &amp;#39;YOUR CONSUMER KEY HERE&amp;#39;
consumer_secret &amp;lt;- &amp;#39;COPY AND PASTE YOUR CONSUMER SECRET HERE&amp;#39;
access_token &amp;lt;- &amp;#39;THEN PUT YOUR ACCESS TOKEN HERE&amp;#39;
access_secret &amp;lt;- &amp;#39;AND YOUR ACCESS SECRET HERE&amp;#39;
setup_twitter_oauth(consumer_key, consumer_secret, access_token=NULL, access_secret=NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running that last line in the chunk should then direct you to your default browser. This will log you into your Twitter account and R will ask for Twitter’s permission to enter through the back door.&lt;/p&gt;
&lt;p&gt;The next bit of code won’t run the way I have it set up because Twitter doesn’t let you download tweets older than a week old. So if you want to play with tweets from a conference’s hashtag or some event, make sure to think ahead to download them!!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;amsTwitter &amp;lt;- searchTwitter(&amp;quot;#smt2017&amp;quot;, n = 700)
amsTwitter &amp;lt;- searchTwitter(&amp;quot;#amsroc17&amp;quot;, n = 1600)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This line above searches Twitter for anything matching the conference hashtags and saves the output of it in a list. You can also include an argument asking for a certain number of tweets, which I’ve also done. Luckily the twitteR package has a function that will take this list and convert it to a data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;amsTwitter.df &amp;lt;- twListToDF(amsTwitter)
smtTwitter.df &amp;lt;- twListToDF(smtTwitter)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these nice data frames, we’ll soon be able to join them together and count up some tweets! In order to do this we can take advantage of the &lt;a href=&#34;https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html&#34;&gt;data.table&lt;/a&gt; package to join our two tables together. Of course there are other ways, but Ben over at &lt;a href=&#34;https://gormanalysis.com/&#34;&gt;Gorm Analytics&lt;/a&gt; sold me on data.table this past summer and since then I have really been loving its easy syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;amsTwitter.dt &amp;lt;- data.table(amsTwitter.df)
smtTwitter.dt &amp;lt;- data.table(smtTwitter.df)
amstweets &amp;lt;- amsTwitter.dt[, .(amsTweets = .N), by=screenName][order(-amsTweets)]
smttweets &amp;lt;- smtTwitter.dt[, .(smtTweets = .N), by=screenName][order(-smtTweets)]
totalTweets &amp;lt;- merge(smttweets,amstweets, on =&amp;quot;screenName&amp;quot;, all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first thing the above code does is swap our data frames over to data.tables. Once they are in the data.table format, we can count up the tweets by screen name, then list them from biggest to smallest all in the same line. From there we merge the two together via the shared column, making sure to grab every instance in each table since not every Tweeter tweeted with both hashtags.&lt;/p&gt;
&lt;p&gt;We then need to clean up some of the NAs (which as a data.table are characters!) in our bigger dataset with R’s ifelse() function that basically works exactly like an ifelse statement would in Microsoft Excel. It looks over a column in your dataset, checks if a value is an NA, if it is then it gives it a 0, if not, it puts in the value that was there in the first place. After replacing NAs, I then make a new variable that adds together both columns then run our final line that prints out our final dataset from top to bottom.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;totalTweets$smtTweets &amp;lt;- ifelse(test = is.na(totalTweets$smtTweets),
                                yes = 0,
                                no = totalTweets$smtTweets) 
totalTweets$amsTweets &amp;lt;- ifelse(test = is.na(totalTweets$amsTweets),
                                yes = 0,
                                no = totalTweets$amsTweets) 

totalTweets[, TotalTweets := smtTweets + amsTweets]
totalTweets[order(-TotalTweets)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here it was simply a matter of using an &lt;a href=&#34;http://www.convertcsv.com/csv-to-html.htm&#34;&gt;online converter&lt;/a&gt; to turn it our final table an html file and then ssh it up to our &lt;a href=&#34;http://musiccog.lsu.edu/&#34;&gt;Music Cognition at LSU&lt;/a&gt; server! Since then I’ve also added both the 2017 &lt;a href=&#34;https://musiccog.lsu.edu/davidjohnbaker/data/amsmt17twitterdata/AmtTwitterData.csv&#34;&gt;AMS&lt;/a&gt; and &lt;a href=&#34;https://musiccog.lsu.edu/davidjohnbaker/data/amsmt17twitterdata/SmtTwitterData.csv&#34;&gt;SMT&lt;/a&gt; datasets that I used to generate the counts in case you want to try this for yourself.&lt;/p&gt;
&lt;p&gt;If anyone has any questions on this, please &lt;a href=&#34;https://twitter.com/DavidJohnBaker&#34;&gt;tweet me&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calculating iMultisets in R</title>
      <link>/post/calculating-imultisets-in-r/</link>
      <pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/calculating-imultisets-in-r/</guid>
      <description>&lt;p&gt;November is pretty much the worst month for people in higher education. There are too many deadlines and if you’re still in coursework (like myself) you have essays to write, presentations to make, and a backlog of homework assigments to grade. So if you can save time here or there, it’s usually a good choice.&lt;/p&gt;
&lt;p&gt;This weekend I was working a homework assingment for my Transformational Theory seminar where we were given a number of pairs of pitch class sets and had to calculate the imultiset for each following Joseph Straus’ 2014 article on &lt;a href=&#34;http://www.mtosmt.org/issues/mto.14.20.2/mto.14.20.2.straus.html&#34;&gt;Total Voice Leading&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As I looked at the top of the assigment (pictured below) and started to crank out the first one by hand, I realized that the next 30 minutes of my life were going to be doing the same thing over and over again.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/imultiset.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Usually if I get that feeling my next thought is “Can I make a computer do this?” and after thinking about it for two minutes I realized the answer was yes.&lt;/p&gt;
&lt;p&gt;So instead of doing all of these by hand, I wrote an R script and with the time saved figured I’d write a quick post about it.&lt;/p&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Problem&lt;/h2&gt;
&lt;p&gt;In order to calculate the imultiset you need two pitch class sets, in this case X and Y. Each set can have any number of pitch classes in them and what you need to do is calculate the distance in &lt;a href=&#34;http://openmusictheory.com/mod12.html&#34;&gt;Modulo 12 space&lt;/a&gt; between every possible combination of pitch classes from one set to the other. So for example, you could move from 4 (E in Mod 12 for you non-music theory readers) to 7, 11, 2, or 5 (G, B, D, or F) resulting in four intervals: {3,7,10,1}. These four numbers in the {curly braces} are what you get when you subtract each number in the second set from the note E in Mod 12 space. This action then needs to be completed for every pair.&lt;/p&gt;
&lt;p&gt;When you need to account for every pairing you need to do a &lt;a href=&#34;https://www.w3resource.com/sql/joins/cross-join.php&#34;&gt;cross join&lt;/a&gt;. A cross join connects each member of one set to each member of another set. This creates the sets of pairs seen below.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/imultisetcj.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Then all you need to do is subtract one from the other to get the distance. The only problem is that these subtractions need to happen in Mod 12 space so in any case where you are subtracting a bigger number from a smaller number you will get a negative result! This is easily fixed by just adding 12 to that number in order to get what we &lt;em&gt;should&lt;/em&gt; have been our answer if we were doing Mod 12 arithmatic.&lt;/p&gt;
&lt;p&gt;After fixing the Mod 12 problem, you’ll have a nice list of intervals that just have to be sorted from top to bottom to have your imultiset. So let’s see how you would do this line by line.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R Code&lt;/h2&gt;
&lt;p&gt;First, let’s get two pitch class sets. In this case we have a C major triad and a G dominant chord.&lt;/p&gt;
&lt;p&gt;X = {0,4,7} and Y = {7,11,2,5}&lt;/p&gt;
&lt;p&gt;Let’s first assign each chord to an object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(0,4,7)
Y &amp;lt;- c(7,11,2,5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we need to do that cross join, which we can accompish with R’s merge() function. This makes us a data frame with every combination from set X and set Y. Below we see the function’s output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Example &amp;lt;- merge(X,Y,all=TRUE)
Example&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    x  y
## 1  0  7
## 2  4  7
## 3  7  7
## 4  0 11
## 5  4 11
## 6  7 11
## 7  0  2
## 8  4  2
## 9  7  2
## 10 0  5
## 11 4  5
## 12 7  5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once having each combination, we then subtract one set from the other. Since I don’t know how to put R into Music Theory Mode where it only operates in Mod 12, we can fix the problem of the negative numbers by just indexing through our answer with in ifelse() statement to replace any negative values with the answer we actually want by adding 12 to it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Example$diff &amp;lt;- Example$y - Example$x
Example$diff&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  7  3  0 11  7  4  2 -2 -5  5  1 -2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Example$mod12 &amp;lt;- ifelse(test = Example$diff &amp;lt; 0 , 
                        yes = Example$diff + 12, 
                        no = Example$diff)
Example$mod12&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  7  3  0 11  7  4  2 10  7  5  1 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With our numbers then in Mod 12 space, we just sort them and we get our imultiset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sort(Example$mod12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0  1  2  3  4  5  7  7  7 10 10 11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course you are not going to want to write this out every time you want to calculate an imultiset, so best to just write a function that does what we just did.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;calculate.multiset &amp;lt;- function(x,y){
  array.1 &amp;lt;- x 
  array.2 &amp;lt;- y
  cross.join &amp;lt;- merge(array.1,array.2, all = TRUE)
  cross.join$diff &amp;lt;- cross.join$y - cross.join$x
  cross.join$mod12 &amp;lt;- ifelse(cross.join$diff &amp;lt; 0, cross.join$diff + 12, cross.join$diff)
  sort(cross.join$mod12)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
