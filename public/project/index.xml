<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on David John Baker</title>
    <link>/project/</link>
    <description>Recent content in Projects on David John Baker</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 David John Baker</copyright>
    <lastBuildDate>Sat, 07 Apr 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/project/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Music Industry</title>
      <link>/project/music-industry/</link>
      <pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/music-industry/</guid>
      <description>

&lt;p&gt;In addition to academic work, I&amp;rsquo;m also often involved as working as a consultant for various music industry projects.
One of the great things about working in &lt;a href=&#34;https://twitter.com/search?q=%23musicscience&#34; target=&#34;_blank&#34;&gt;#musicscience&lt;/a&gt; is that there is a bit more opportunity to do consultancy work where theory can meet practice.
If you&amp;rsquo;d like to hire me for anything from trying to find insight from your dirty data, to making data products, to scientific consultancy, please don&amp;rsquo;t hesitate to &lt;a href=&#34;mailto:davidjohnbaker1@gmail.com&#34; target=&#34;_blank&#34;&gt;get in touch&lt;/a&gt;!!&lt;/p&gt;

&lt;p&gt;Here are some examples of projects that I have been involved with in the past.&lt;/p&gt;

&lt;h2 id=&#34;projects&#34;&gt;Projects&lt;/h2&gt;

&lt;h3 id=&#34;soundscape&#34;&gt;Soundscape&lt;/h3&gt;

&lt;p&gt;This summer I am currently involved on a project with &lt;a href=&#34;https://soundscapeagency.com/&#34; target=&#34;_blank&#34;&gt;Soundscape Agency&lt;/a&gt; acting as their scientific consultant to help develop music in collaboration with various artists from the &lt;a href=&#34;https://www.erasedtapes.com/&#34; target=&#34;_blank&#34;&gt;Erased Tapes&lt;/a&gt; record label.
More information to come soon!&lt;/p&gt;

&lt;h3 id=&#34;soundout&#34;&gt;Soundout&lt;/h3&gt;

&lt;p&gt;Working with &lt;a href=&#34;https://www.soundout.com/&#34; target=&#34;_blank&#34;&gt;Soundout&lt;/a&gt;, I worked on a project with their lead data scientist &lt;a href=&#34;https://www.linkedin.com/in/tabitha-trahan/&#34; target=&#34;_blank&#34;&gt;Tabi Trahan&lt;/a&gt; and Dr. &lt;a href=&#34;http://www.doc.gold.ac.uk/~mas03dm/&#34; target=&#34;_blank&#34;&gt;Daniel Müllensifen&lt;/a&gt; to develop a tool that mapped Music and Brand personality onto the same emotional space.
The details of the project can be found in the &lt;a href=&#34;https://www.researchgate.net/publication/306374399_Matching_Music_to_Brand_Personality_A_Semantic_Differential_Tool_for_Measuring_Emotional_Space&#34; target=&#34;_blank&#34;&gt;proceedings of the 14th International Conference on Music Perception and Cognition&lt;/a&gt;.
The tool served as the basis for what later became their &lt;a href=&#34;https://www.soundout.com/brandmatch&#34; target=&#34;_blank&#34;&gt;BrandMatch&lt;/a&gt; tool.&lt;/p&gt;

&lt;h3 id=&#34;audio-branding-academy&#34;&gt;Audio Branding Academy&lt;/h3&gt;

&lt;p&gt;In 2014 I presented with Dr. Daniel Müllensifen at the Audio Branding Academy annual conference in Berlin, Germany.
We gave a half-day workshop on tools that help bridge gaps between academics, creatives, and industry minded people.
A summary of our workshop can be found in their &lt;a href=&#34;https://www.researchgate.net/publication/284721150_Music_Brands_Advertising_Testing_What_Works&#34; target=&#34;_blank&#34;&gt;annual yearbook from that year&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Computational Musicology</title>
      <link>/project/computational-musicology/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/computational-musicology/</guid>
      <description>&lt;p&gt;Computational Musicology involves using computers to digitize musical data and then using powerful software to search through massive amounts of data that would be unfeasible to do by hand. I am particularly interested in using symbolic data to extract information from melodies that can be used to predict how well melodies are remembered and creating new data sets that others can use.&lt;/p&gt;

&lt;p&gt;One project involving creating new datasets involves curating a dataset of improvised jazz solos.
In its current state, the corpus is encoded in **kern and has solos from Charlie Parker (~70), Clifford Brown (~80), as well as Dizzy Gillespie (~10).
We are in the process of including data from Miles Davis, John Coltrane, as well as other artists.
Though not publicly availible yet, the dataset will have both melodic as well as harmonic information and be easily indexed using the &lt;a href=&#34;http://www.humdrum.org/&#34; target=&#34;_blank&#34;&gt;Humdrum&lt;/a&gt; tool kit.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Modeling Melodic Dictation</title>
      <link>/project/music-and-memory/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/music-and-memory/</guid>
      <description>

&lt;p&gt;All students pursuing a Bachelor&amp;rsquo;s degree in Music from universities accredited by the National
Association of Schools of Music must learn to take melodic dictation.
This skill is a demanding process that requires students to listen to a melody, retain it in memory, and then use their knowledge of Western musical notation to recreate the mental image of the melody on paper in a limited time frame.
For many, becoming proficient at this task is at the core of developing their aural skills.&lt;/p&gt;

&lt;h2 id=&#34;structure-and-highlights-of-the-dissertation&#34;&gt;Structure and Highlights of the Dissertation&lt;/h2&gt;

&lt;p&gt;In my dissertation I investigate factors thought to contribute to how people learn melodies by drawing on my experience from both cognitive psychology and computational musicology.
I am currently in the process of writing and welcome any thoughts of questions on the research!
Below I outline the main goals of each chapter along with methods and novel findings from the research:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Chapter I: Background and Theoretical Rationale

&lt;ul&gt;
&lt;li&gt;Establishes why tools from computational musicology and cognitive psychology are best suited to answer questions about melodic dictation.&lt;/li&gt;
&lt;li&gt;Catalogs and taxonomizes features thought to contribute to melodic dictation&lt;/li&gt;
&lt;li&gt;Argues for polymorphic view of modeling musical ability&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chapter II: History and Mental Representation

&lt;ul&gt;
&lt;li&gt;Reviews history and current state of aural skills pedagogy&lt;/li&gt;
&lt;li&gt;Asserts historical questions of aural skills pedagogy can be better understood by recontextualizing them as questions of mental representation of musical material&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chapter III: Insights from Cognitive Psychology

&lt;ul&gt;
&lt;li&gt;Uses cross-sectional experimental design to investigate individual abilities thought to contribute to tasks of musical perception&lt;/li&gt;
&lt;li&gt;Data analyzed using structural equation modeling&lt;/li&gt;
&lt;li&gt;Findings suggest working memory capacity to be good predictor in tasks of musical perception&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chapter IV: Computational Features

&lt;ul&gt;
&lt;li&gt;Asserts that computationally abstracted features from melodies can be used as quantitative stand in for musical intuitions&lt;/li&gt;
&lt;li&gt;Discusses how these features can be used to help aural skills pedagogues determine difficulty of melodies&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chapter V: Dictation Corpus

&lt;ul&gt;
&lt;li&gt;Introduces new 600+ melody corpus&lt;/li&gt;
&lt;li&gt;Describes corpus&amp;rsquo; features and possible uses&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Chapter VI: Experiments and Computational Model

&lt;ul&gt;
&lt;li&gt;Synthesizes all aforementioned factors in dual experiments investigating how predictive abstracted features are in experimental setting&lt;/li&gt;
&lt;li&gt;Posits computational model of melodic dictation&lt;/li&gt;
&lt;li&gt;Discusses how computational model can inform both perceptual research and inform pedagogical practice.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;dissertation-output&#34;&gt;Dissertation Output&lt;/h2&gt;

&lt;p&gt;Full referencing to be added soon.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;First author&lt;/strong&gt; on article currently revised and resubmitted at &lt;em&gt;Musicae Scientiae&lt;/em&gt; replicating the &lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0089642&#34; target=&#34;_blank&#34;&gt;Goldsmiths Musical Sophistication Index&lt;/a&gt; that offers additional commentary on the use of latent variables in music research. Argues for researchers to adopt a polymorphic view of musical ability when creating statistical models. Materials from first and third Chapter&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;First author&lt;/strong&gt; on tentatively accepted book chapter with Routledge in &lt;em&gt;Companion to Aural Training in Music Education&lt;/em&gt;. Materials from sixth Chapter.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;First author&lt;/strong&gt; on chapter in &lt;em&gt;Scholarly Approaches to Mathematical Music Theory&lt;/em&gt;. Materials from sixth chapter&lt;/li&gt;
&lt;li&gt;Two &lt;strong&gt;First author&lt;/strong&gt; International Conference on Music Perception and Cognition proceedings papers available on my &lt;a href=&#34;https://www.researchgate.net/profile/David_Baker45&#34; target=&#34;_blank&#34;&gt;Research Gate&lt;/a&gt;. Materials from third and sixth chapter.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Music Cognition and Computation Lab</title>
      <link>/project/lsu-lab-external/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/lsu-lab-external/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
