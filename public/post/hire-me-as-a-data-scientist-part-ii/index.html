<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.26" />
  <meta name="author" content="David John Baker">
  <meta name="description" content="PhD Student, Music Cognition and Computation Lab">

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.0/css/academicons.min.css" integrity="sha512-GGGNUPDhnG8LEAEDsjqYIQns+Gu8RBs4j5XGlxl7UfRaZBhCCm5jenJkeJL8uPuOXGqgl8/H1gjlWQDRjd3cUQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-109897649-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="David John Baker">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="David John Baker">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="/post/hire-me-as-a-data-scientist-part-ii/">

  

  <title>Hire Me (as a Data Scientist!), Part II | David John Baker</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">David John Baker</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Hire Me (as a Data Scientist!), Part II</h1>
    

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2018-01-15 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Mon, Jan 15, 2018
    </time>
  </span>

  
  
  
  <span class="article-categories">
    <i class="fa fa-folder"></i>
    
    <a href="/categories/r">R</a
    >, 
    
    <a href="/categories/10-minute-reads">10 Minute Reads</a
    >
    
  </span>
  
  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/tags/r">R</a
    >, 
    
    <a href="/tags/data-science">Data Science</a
    >, 
    
    <a href="/tags/beer">Beer</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fhire-me-as-a-data-scientist-part-ii%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Hire%20Me%20%28as%20a%20Data%20Scientist%21%29%2c%20Part%20II&amp;url=%2fpost%2fhire-me-as-a-data-scientist-part-ii%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fhire-me-as-a-data-scientist-part-ii%2f&amp;title=Hire%20Me%20%28as%20a%20Data%20Scientist%21%29%2c%20Part%20II"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fhire-me-as-a-data-scientist-part-ii%2f&amp;title=Hire%20Me%20%28as%20a%20Data%20Scientist%21%29%2c%20Part%20II"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Hire%20Me%20%28as%20a%20Data%20Scientist%21%29%2c%20Part%20II&amp;body=%2fpost%2fhire-me-as-a-data-scientist-part-ii%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    <div class="article-style" itemprop="articleBody">
      <div id="beer-reccomendation" class="section level2">
<h2>Beer Reccomendation</h2>
<p>Continuing on from my earlier post, I’m now looking to tackle the question:</p>
<blockquote>
<p>If you had to pick 3 beers to recommend using only this data, which would you pick?</p>
</blockquote>
<p>This is a pretty open ended question, which is kind of fun. I also don’t really have a ton of experience (yet!) in recommendation systems, though I have done a little reading here or there on it.</p>
<p>My goals in coming up with three beers to recommend were to:</p>
<ol style="list-style-type: decimal">
<li>Try to find the most popular beer among super users of the website</li>
<li>Find a <a href="https://youtu.be/IcjSDZNbOs0?t=31s">bizzaro</a> beer that matched the profile of my first beer, but lives in the <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=DTeZAAAAQBAJ&amp;oi=fnd&amp;pg=PT6&amp;dq=anderson+2006+long+tail&amp;ots=MpaGpMbdfD&amp;sig=25QPk_RCCNU2yFoo9nsU0hrt0sc#v=onepage&amp;q=anderson%202006%20long%20tail&amp;f=false">long tail</a> of the ratings distribution</li>
<li>Find the best Beer sans Booze (Highest Rating with lowest ABV)</li>
</ol>
<p>So let’s begin! Here’s how I went about tackling this question.</p>
</div>
<div id="popular-with-super-users" class="section level2">
<h2>Popular with Super Users</h2>
<pre class="r"><code>#=====================================================================================#
# Following suit of the last post... 
#=====================================================================================#
# Library
library(ggplot2)
library(data.table)
library(stringr)
#=====================================================================================#
beer &lt;- fread(&quot;data/beer_reviews.csv&quot;)</code></pre>
<pre><code>## 
Read 83.8% of 1586614 rows
Read 1586614 rows and 13 (of 13) columns from 0.168 GB file in 00:00:03</code></pre>
<pre class="r"><code>beer.complete &lt;- beer[complete.cases(beer)]
#=====================================================================================#</code></pre>
<p>Having had more experience in experimental settings first, one of the first things that I needed to get used to when I started working with non-psychology datasets is the lack of complete sets in what feel like almost everything. Whereas in the <a href="https://musiccog.lsu.edu/">lab</a> we spend lots of time trying to design balanced studies that hopefully don’t violate the litany of assumptions that classic null hypothesis significance testing demands, my first few attempts at analyzing large amounts of data made me realize it’s almost risible to think that you’re going to have even, independent data, ever. This dataset is no different.</p>
<p>Of all of the unique users on the site, most of them only have done a couple of reviews, but some have essentially made a job out of this. Looking at the distribution of reviews, this is quite clear.</p>
<pre class="r"><code>review.counts &lt;- beer[, .(.N), by = review_profilename][order(-N)]
review.counts </code></pre>
<pre><code>##        review_profilename    N
##     1:     northyorksammy 5817
##     2:      BuckeyeNation 4661
##     3:        mikesgroove 4617
##     4:          Thorpe429 3518
##     5:      womencantsail 3497
##    ---                        
## 33384:          beilfussd    1
## 33385:         MPHSours11    1
## 33386:         jennaizzel    1
## 33387:           hogshead    1
## 33388:            joeebbs    1</code></pre>
<pre class="r"><code>hist(beer[, .(.N), by = review_profilename][order(-N)]$N, 
     breaks = 200,
     xlab = &quot;Number of Reviews&quot;,
     main = &quot;Distribution of Reviews Per User&quot;)</code></pre>
<p><img src="/post/2018-01-14-hire-me-as-a-data-scientist-part-ii_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>This is pretty important when it comes to modeling the data (discussed in Part III) and not being fully aware of where your ratings are coming from could seriously put the quality of your models at risk.</p>
<p>So looking at this dataset, I was wondering if there were any sort of implicit assumptions I could make about the data here that might be able to help me find a good beer. One assumption that I don’t think is too wild is that a sample of this population who have gone out of their way and rated over 500 beers probably are more of beer experts than those who have only done a couple of reviews on the site.</p>
<p>One thing I wanted to check is of all the 1.5 million reviews, where are all of these reviews coming from? Are there enough reviews among the super users that we could use? And what makes someone a super user? I could have been a bit more scientific setting an <em>a priori</em> threshold, but for this I kind of just looked at that chart above, spit balled thinking 500 might be a good number to check, and then went to see how much of the data is accounted if I put my threshold there. I lucked out and got about half of it.</p>
<pre class="r"><code>sum(review.counts$N) # Number of Total Reviews </code></pre>
<pre><code>## [1] 1586614</code></pre>
<pre class="r"><code>sum(review.counts[ N &gt; 500]$N) # Number of Reviews from Super Users</code></pre>
<pre><code>## [1] 731066</code></pre>
<pre class="r"><code>731066/1586614 # Percent of Total Reviews from 500+ Super Users</code></pre>
<pre><code>## [1] 0.4607712</code></pre>
<pre class="r"><code>super.users &lt;- review.counts[ N &gt;  500] # I can settle for .75 Million Reviews</code></pre>
<p>So now we have a list of the users who have done over 500 reviews who make up 46% of our entire data. We can use this new table we’ve made to index through our dataset of all the reviews that we have (that have their ABV ratings!) so we are only dealing with these higher quality reviewers.</p>
<pre class="r"><code>super.reviews &lt;- super.users[beer.complete, on = &quot;review_profilename&quot;, nomatch=0]</code></pre>
<p>As we continue to chop down our dataset (since this is a very exploratory process compared with cleaning up an experiment), it’s important to do <strong>quality assesment</strong> steps. One thing worth checking here is to see if we are actually dealing with beer omnivores in our super users and make sure that all different types of beers are being represented in our smaller subset. This can be done but just looking at the number of rows between the original dataset and our super user table.</p>
<pre class="r"><code>super.reviews[, .(beer_styles = unique(beer_style))]</code></pre>
<pre><code>##                          beer_styles
##   1:                      Hefeweizen
##   2:              English Strong Ale
##   3:          Foreign / Export Stout
##   4:                 German Pilsener
##   5:  American Double / Imperial IPA
##  ---                                
## 100:             Japanese Rice Lager
## 101:                      Roggenbier
## 102:                        Happoshu
## 103:                           Sahti
## 104: Bière de Champagne / Bière Brut</code></pre>
<pre class="r"><code>beer[, .(beer_styles = unique(beer_style))]</code></pre>
<pre><code>##                          beer_styles
##   1:                      Hefeweizen
##   2:              English Strong Ale
##   3:          Foreign / Export Stout
##   4:                 German Pilsener
##   5:  American Double / Imperial IPA
##  ---                                
## 100:                          Gueuze
## 101:                            Gose
## 102:                        Happoshu
## 103:                           Sahti
## 104: Bière de Champagne / Bière Brut</code></pre>
<p>Luckily they are the same. If I were to really do some more work on this dataset, I would also want to check things such as how many of the beers has each super user tried? Are there IPA experts in the group? If yes, should their opinion be taken more seriously if I had questions about IPA recommendation in the future? But for now, I just set out to see what is the highest rated beer among all the super users of this dataset.</p>
<p>In order to answer that question, we need to be able to find out which beer in specific has the highest mean rating. The dataset as is comes with a <code>beer_id</code> unique ID, but the data downloaded as is does not give us a key to this so we have to make it ourselves. This can be accomplished by just pasting together the brewery’s name, along with the beer name, and style into a new variable.</p>
<p>As another <strong>quality assurance</strong> step, it’s worth checking to see if this recreated the unique ID variable, which it didn’t do exactly… but it’s pretty close. I would chalk that up to some sort of encoding error.</p>
<pre class="r"><code>super.reviews[, beer_name_unique := paste(brewery_name,beer_name, beer_style)]

length(unique(super.reviews$beer_beerid))</code></pre>
<pre><code>## [1] 42825</code></pre>
<pre class="r"><code>length(unique(super.reviews$beer_name_unique))</code></pre>
<pre><code>## [1] 42703</code></pre>
<pre class="r"><code>42703/42805 # Pretty close</code></pre>
<pre><code>## [1] 0.9976171</code></pre>
<pre class="r"><code>super.reviews.popular &lt;- super.reviews[, .(most_reviewed_beers = .N), 
                                       by = beer_name_unique][order(-most_reviewed_beers)]

hist(super.reviews.popular$most_reviewed_beers,
     main = &quot;Distribution of Number of Ratings by Super Users&quot;,
     xlab = &quot;Number of Reviews each Beer Recieves&quot;,
     breaks = 200)</code></pre>
<p><img src="/post/2018-01-14-hire-me-as-a-data-scientist-part-ii_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Again we see this is clearly <strong>not</strong> anything resembling a repeated measures experiment and not all beers were rated equally.</p>
<p>Continuing in the same fashion above let’s grab just the top 100 beers of our super users and then merge that on to our table from earlier that had all of the ratings from our super users. Then of that table, let’s just take the average of the overall rating and look at our top ten beers.</p>
<pre class="r"><code>super.reviews.popular.100 &lt;- super.reviews[, .(most_reviewed_beers = .N), by = beer_name_unique][order(-most_reviewed_beers)][1:100]

super.reviews.cream.of.crop &lt;- super.reviews.popular.100[super.reviews, 
                                                         on = &quot;beer_name_unique&quot;, 
                                                         nomatch=0]

super.reviews.cream.of.crop[, .(mean_review_overall = mean(review_overall)), by = beer_name_unique][order(-mean_review_overall)][1:10]</code></pre>
<pre><code>##                                                                                      beer_name_unique
##  1:                      Russian River Brewing Company Pliny The Elder American Double / Imperial IPA
##  2:                  Bayerische Staatsbrauerei Weihenstephan Weihenstephaner Hefeweissbier Hefeweizen
##  3:                              Tröegs Brewing Company Tröegs Nugget Nectar American Amber / Red Ale
##  4:                                 Ballast Point Brewing Company Sculpin India Pale Ale American IPA
##  5:                 Three Floyds Brewing Co. &amp; Brewpub Dreadnaught IPA American Double / Imperial IPA
##  6: Founders Brewing Company Founders KBS (Kentucky Breakfast Stout) American Double / Imperial Stout
##  7:                                                 Bell&#39;s Brewery, Inc. Two Hearted Ale American IPA
##  8:                            Bell&#39;s Brewery, Inc. Bell&#39;s Hopslam Ale American Double / Imperial IPA
##  9:                    Three Floyds Brewing Co. &amp; Brewpub Alpha King Pale Ale American Pale Ale (APA)
## 10:                Founders Brewing Company Founders Breakfast Stout American Double / Imperial Stout
##     mean_review_overall
##  1:            4.536630
##  2:            4.535072
##  3:            4.449084
##  4:            4.443287
##  5:            4.367580
##  6:            4.366876
##  7:            4.353270
##  8:            4.349810
##  9:            4.346652
## 10:            4.334526</code></pre>
<p>And we have our winner! It’s <a href="https://www.beeradvocate.com/beer/profile/863/7971/">Pliny The Elder</a> from Russian River Brewing Company as my first beer recommendation!</p>
</div>
<div id="bizzaro-beer" class="section level2">
<h2>Bizzaro Beer</h2>
<p>Now Pliny The Elder seems to be a pretty popular beer. But what if we are trying to sketch out some ideas about what other beers that we could recommend to beer lovers who like Pliny The Elder? It needs to somewhat “look like” our target beer, but needs to have way less reviews.</p>
<p>Playing with some of the fringe data here, I want to be careful not to again pick a beer with only one or two ratings on it. My rationale coming from assuming there is some sort of true “population mean” for this beer and having a beer with too little reviews will not approximate the mean correctly.</p>
<pre class="r"><code>## Make Unique Beer Label for Larger Dataset
beer[, beer_name_unique := paste(brewery_name,beer_name, beer_style)]

## Count Number of Reviews Each Beer Has  
number.of.reviews &lt;- beer[, .(NumberOfReviews = .N), by = beer_name_unique][order(-NumberOfReviews)]
 
## Only get beers with over 30 reviews
reliable.beers.list &lt;- number.of.reviews[ NumberOfReviews &gt;= 30 ]

## Join that to our big &#39;beer&#39; dataset only matching beers with over 30 reviews
beer.reliable &lt;- reliable.beers.list[beer, on = &quot;beer_name_unique&quot;, nomatch=0]</code></pre>
<p>With our dataset chiseled down to only ‘reliable’ beers, I needed to find a way to get some sort of profile of each of the beers. While my first instinct was to do some sort of data reductive type thing like do a PCA on our continuous variables and use distances from certain scores as metrics of similarity (<a href="https://musiccog.lsu.edu/davidjohnbaker/papers/Baker_Trahan_Mullensiefen_ProceedingsPaper.pdf">which I have done before</a> and it ended up actually being the inspiration for a tool currently used by <a href="https://www.soundout.com/brandmatch">Soundout</a>!), doing that on so few predictors seemed <a href="https://www.urbandictionary.com/define.php?term=extra">extra</a>.</p>
<p>So instead I figured why not just assume that there is some sort of wiggle room in my hastily made recommendation system and just match first on the overall review, then if there are some close contenders, look for matches on other metrics?</p>
<p>The next bit of code creates a table of the metrics I am interested in, gets beers that have over 30 reviews, but less than 100, and also creates a vector so I can pull out all of the IPAs on my less reviewed beers table. I then join the tables for my candidates.</p>
<pre class="r"><code># # Get metrics used for distance calculations
beer.metrics &lt;- beer.reliable[, .(mean_review_overall = mean(review_overall),
                                  mean_review_aroma = mean(review_overall),
                                   mean_review_appearance = mean(review_appearance),
                                   mean_review_palate = mean(review_palate),
                                   mean_reviw_taste = mean(review_taste),
                                   sd_review_overall = sd(review_overall),
                                   sd_review_aroma = sd(review_overall),
                                   sd_review_appearance = sd(review_appearance),
                                   sd_review_palate = sd(review_palate),
                                   sd_review_taste = sd(review_taste)),
                               by = beer_name_unique]

## Get only IPAs with less than 100 reviews
less.reviewed.beers &lt;- number.of.reviews[NumberOfReviews &lt;= 100 &amp; NumberOfReviews &gt;= 30]
## Make vector to help find IPAs
find.IPA &lt;- str_detect(string = less.reviewed.beers$beer_name_unique, pattern = &quot;Imperial IPA&quot;)
bizzaro.candidates &lt;- less.reviewed.beers[find.IPA]

#Create Table
bizzaro.candidates.metrics &lt;- bizzaro.candidates[beer.metrics, on = &quot;beer_name_unique&quot;, nomatch=0]</code></pre>
<p>Of these less reviewed beers, we now need to find the one that is “closest” on the few dimensions we have to work with. The simplest way to do this would be to just subtract our target beer (Pliny The Elder), from every other beer in our interested list, then check out the results.</p>
<pre class="r"><code>## Get metrics for our target beer
rrbcpteadii.metrics &lt;- beer[beer_name_unique == &quot;Russian River Brewing Company Pliny The Elder American Double / Imperial IPA&quot;,
                           .(mean_review_overall = mean(review_overall),
                             mean_review_aroma = mean(review_overall),
                             mean_review_appearance = mean(review_appearance),
                             mean_review_palate = mean(review_palate),
                             mean_reviw_taste = mean(review_taste),
                             sd_review_overall = sd(review_overall),
                             sd_review_aroma = sd(review_overall),
                             sd_review_appearance = sd(review_appearance),
                             sd_review_palate = sd(review_palate),
                             sd_review_taste = sd(review_taste))]
## Create vector for looping over
key.vector &lt;- as.vector(rrbcpteadii.metrics)
## Pull off the tags of our search
search.vector &lt;- bizzaro.candidates.metrics[, -c(1,2)]

## Sanity check that what we are going to subtract has same names
names(key.vector)</code></pre>
<pre><code>##  [1] &quot;mean_review_overall&quot;    &quot;mean_review_aroma&quot;     
##  [3] &quot;mean_review_appearance&quot; &quot;mean_review_palate&quot;    
##  [5] &quot;mean_reviw_taste&quot;       &quot;sd_review_overall&quot;     
##  [7] &quot;sd_review_aroma&quot;        &quot;sd_review_appearance&quot;  
##  [9] &quot;sd_review_palate&quot;       &quot;sd_review_taste&quot;</code></pre>
<pre class="r"><code>names(search.vector)</code></pre>
<pre><code>##  [1] &quot;mean_review_overall&quot;    &quot;mean_review_aroma&quot;     
##  [3] &quot;mean_review_appearance&quot; &quot;mean_review_palate&quot;    
##  [5] &quot;mean_reviw_taste&quot;       &quot;sd_review_overall&quot;     
##  [7] &quot;sd_review_aroma&quot;        &quot;sd_review_appearance&quot;  
##  [9] &quot;sd_review_palate&quot;       &quot;sd_review_taste&quot;</code></pre>
<pre class="r"><code>## And that the apply function I am going to run is doing what I think it will
search.vector[1]- key.vector</code></pre>
<pre><code>##    mean_review_overall mean_review_aroma mean_review_appearance
## 1:          -0.7900277        -0.7900277             -0.6386031
##    mean_review_palate mean_reviw_taste sd_review_overall sd_review_aroma
## 1:         -0.6263257       -0.8393187        0.09103239      0.09103239
##    sd_review_appearance sd_review_palate sd_review_taste
## 1:            0.1273011          0.11882       0.1073594</code></pre>
<pre class="r"><code>## Run apply function
ipa.distances &lt;- apply(search.vector, 1, function(x) x - key.vector)
ipa.distances.dt &lt;- data.table(do.call(rbind.data.frame,ipa.distances))
## Combine this back with vector with names
bizzaro.candidates.distances &lt;- cbind(bizzaro.candidates.metrics, ipa.distances.dt)
## Sort our data by overall and see if we have a good match!
bizzaro.candidates.distances[order(-mean_review_overall)]</code></pre>
<pre><code>##                                                                          beer_name_unique
##   1: Hill Farmstead Brewery Galaxy Imperial Single Hop IPA American Double / Imperial IPA
##   2:           Lawson&#39;s Finest Liquids Double Sunshine IPA American Double / Imperial IPA
##   3:        Kern River Brewing Company 5th Anniversary Ale American Double / Imperial IPA
##   4:                           Alpine Beer Company Bad Boy American Double / Imperial IPA
##   5:             Iron Hill Brewery &amp; Restaurant Kryptonite American Double / Imperial IPA
##  ---                                                                                     
## 132:                            BrewDog Sink The Bismarck! American Double / Imperial IPA
## 133:                   Blue Frog Grog &amp; Grill The Big DIPA American Double / Imperial IPA
## 134:                            Hermitage Brewing Hoptopia American Double / Imperial IPA
## 135:                    Florida Beer Company Swamp Ape IPA American Double / Imperial IPA
## 136:            BrewDog Storm (Islay Whisky Cask Aged IPA) American Double / Imperial IPA
##      NumberOfReviews mean_review_overall mean_review_aroma
##   1:              76            4.592105          4.592105
##   2:              85            4.588235          4.588235
##   3:              41            4.475610          4.475610
##   4:              79            4.468354          4.468354
##   5:              44            4.443182          4.443182
##  ---                                                      
## 132:              76            3.197368          3.197368
## 133:              53            2.867925          2.867925
## 134:              32            2.687500          2.687500
## 135:              52            2.615385          2.615385
## 136:              92            2.440217          2.440217
##      mean_review_appearance mean_review_palate mean_reviw_taste
##   1:               4.368421           4.440789         4.559211
##   2:               4.317647           4.311765         4.552941
##   3:               4.329268           4.219512         4.500000
##   4:               4.234177           4.335443         4.474684
##   5:               4.284091           4.318182         4.420455
##  ---                                                           
## 132:               3.835526           3.401316         3.539474
## 133:               3.433962           3.047170         2.801887
## 134:               3.500000           2.890625         2.500000
## 135:               3.442308           3.009615         2.586538
## 136:               2.902174           2.836957         2.706522
##      sd_review_overall sd_review_aroma sd_review_appearance
##   1:         0.3337716       0.3337716            0.3861642
##   2:         0.3289275       0.3289275            0.3845766
##   3:         0.3865103       0.3865103            0.3641730
##   4:         0.3698733       0.3698733            0.3741267
##   5:         0.3768892       0.3768892            0.3796836
##  ---                                                       
## 132:         1.2438621       1.2438621            0.7136206
## 133:         0.8995241       0.8995241            0.6866707
## 134:         1.2427207       1.2427207            0.4918694
## 135:         0.9108033       0.9108033            0.5994593
## 136:         0.9829379       0.9829379            0.6843587
##      sd_review_palate sd_review_taste mean_review_overall
##   1:        0.3997258       0.3826844         0.002077562
##   2:        0.4293993       0.3620669        -0.001792407
##   3:        0.4749840       0.4873397        -0.114417945
##   4:        0.4060561       0.3660140        -0.121673270
##   5:        0.4586495       0.4026537        -0.146845883
##  ---                                                     
## 132:        1.1431528       1.1277209        -1.392659280
## 133:        0.7355280       0.8165336        -1.722103173
## 134:        0.8005479       0.9418581        -1.902527701
## 135:        0.7637009       1.0035288        -1.974643085
## 136:        0.7883377       1.0086226        -2.149810310
##      mean_review_aroma mean_review_appearance mean_review_palate
##   1:       0.002077562            -0.02018203        -0.01053621
##   2:      -0.001792407            -0.07095603        -0.13956098
##   3:      -0.114417945            -0.05933479        -0.23181349
##   4:      -0.121673270            -0.15442587        -0.11588264
##   5:      -0.146845883            -0.10451218        -0.13314386
##  ---                                                            
## 132:      -1.392659280            -0.55307677        -1.05000989
## 133:      -1.722103173            -0.95464082        -1.40415587
## 134:      -1.902527701            -0.88860309        -1.56070068
## 135:      -1.974643085            -0.94629539        -1.44171030
## 136:      -2.149810310            -1.48642917        -1.61436916
##      mean_reviw_taste sd_review_overall sd_review_aroma
##   1:      -0.07177483       -0.12136909     -0.12136909
##   2:      -0.07804418       -0.12621327     -0.12621327
##   3:      -0.13098536       -0.06863039     -0.06863039
##   4:      -0.15630181       -0.08526747     -0.08526747
##   5:      -0.21053081       -0.07825155     -0.07825155
##  ---                                                   
## 132:      -1.09151167        0.78872139      0.78872139
## 133:      -1.82909857        0.44438341      0.44438341
## 134:      -2.13098536        0.78758001      0.78758001
## 135:      -2.04444690        0.45566254      0.45566254
## 136:      -1.92446362        0.52779720      0.52779720
##      sd_review_appearance sd_review_palate sd_review_taste
##   1:          -0.01935577      -0.04762635     -0.03307969
##   2:          -0.02094339      -0.01795284     -0.05369722
##   3:          -0.04134702       0.02763182      0.07157561
##   4:          -0.03139329      -0.04129607     -0.04975012
##   5:          -0.02583641       0.01129741     -0.01311039
##  ---                                                      
## 132:           0.30810063       0.69580063      0.71195677
## 133:           0.28115074       0.28817587      0.40076950
## 134:           0.08634938       0.35319581      0.52609404
## 135:           0.19393929       0.31634876      0.58776473
## 136:           0.27883874       0.34098558      0.59285853</code></pre>
<p>Of course if we were building a real recommendation machine we could start talking about what factors are more important for what users and what factors are more predictive than others, but this seems like an OK enough solution to at least have completed my <em>a priori</em> goal.</p>
<p>Based on this solution, it looks like I will have to find myself a bottle of <a href="https://www.beeradvocate.com/beer/profile/863/7971/">Pliny The Elder</a> and the <a href="https://www.beeradvocate.com/beer/profile/22511/67760/">Hill Farmstead Brewery Galaxy Imperial Single Hop IPA American Double / Imperial IPA</a> and do some of my own empirical work to see if this was a good idea.</p>
</div>
<div id="beer-sans-booze" class="section level2">
<h2>Beer sans Booze</h2>
<p>The last beer that I think wanted to recommend would be one that tastes great, but does not have a lot of alcohol with it. The reason this question kind of interests me is because if we are <em>really</em> going to talk about how tasty a beer is, it would be nice to be able to factor out of the equation how drunk we are actually getting from it.</p>
<p>We can see first of all IF this relationship exists if we look at the mean overall rating of a beer as a function of its ABV content.</p>
<pre class="r"><code>beer.complete[, beer_name_unique := paste(brewery_name,beer_name, beer_style) ]

# ABVs and Mean Scores
abv.vs.mean &lt;- beer.complete[, .(Abv = mean(beer_abv), MeanOverall = mean(review_overall)), by = beer_name_unique]

ggplot(abv.vs.mean[Abv &lt; 20], aes(x = Abv, y = MeanOverall)) + 
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) +
  geom_smooth(method = &quot;lm&quot;, formula = y ~ poly(x,2), color = &quot;orange&quot;) +
  labs(title = &quot;Rating as Function of ABV (Beers with than 20% ABV)&quot;,
       x = &quot;ABV Content&quot;,
       y = &quot;Mean Overall Rating&quot;)</code></pre>
<p><img src="/post/2018-01-14-hire-me-as-a-data-scientist-part-ii_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Surprisingly, when we run some quick and dirty regression models (that yes, I know violate tons of assumptions) we see that only a very small amount of variance is being explained by its ABV. Note that although the models are significant, the <span class="math inline">\(R^2\)</span> values hover around 3-5%!</p>
<pre class="r"><code># &quot;The More Booze The Better&quot; Model
abv.linear &lt;- lm(MeanOverall ~ Abv, data = abv.vs.mean[Abv &lt; 20]) 
# The &quot;Diminishing Returns Model &quot;
abv.poly &lt;- lm(MeanOverall ~ poly(Abv,2), data = abv.vs.mean[Abv &lt; 20])
# The &quot;Dissapoint Amount of Variance Explained Summaries&quot;
summary(abv.linear)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MeanOverall ~ Abv, data = abv.vs.mean[Abv &lt; 20])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.06793 -0.27278  0.09684  0.38850  1.72081 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 3.276138   0.008995  364.20   &lt;2e-16 ***
## Abv         0.060975   0.001369   44.55   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6013 on 48822 degrees of freedom
## Multiple R-squared:  0.03906,    Adjusted R-squared:  0.03904 
## F-statistic:  1984 on 1 and 48822 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>summary(abv.poly)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MeanOverall ~ poly(Abv, 2), data = abv.vs.mean[Abv &lt; 
##     20])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.88738 -0.28351  0.09695  0.37907  2.17585 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.658087   0.002706 1351.73   &lt;2e-16 ***
## poly(Abv, 2)1  26.785156   0.597970   44.79   &lt;2e-16 ***
## poly(Abv, 2)2 -13.922969   0.597970  -23.28   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.598 on 48821 degrees of freedom
## Multiple R-squared:  0.04961,    Adjusted R-squared:  0.04957 
## F-statistic:  1274 on 2 and 48821 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This actually surprised me and might be worth looking into at a deeper level another time, but for now I want to keep going on and find a beer knowing that how much booze is in it doesn’t really affect how good it is.</p>
<p>So let’s take one final dive into the dataset, grab only our quality reviews then plot a subset of our data so we can see beers that have a very high overall rating with a very small amount of booze in them.</p>
<pre class="r"><code># Quality Assurance Step
reliable.and.abv.beers &lt;- reliable.beers.list[beer.complete, on = &quot;beer_name_unique&quot;, nomatch=0]

## Get mean ratings and keep ABV (which won&#39;t change if I average it)
dd.beers &lt;- reliable.and.abv.beers[, .(mean_overall = mean(review_overall), abv = mean(beer_abv)), by = &quot;beer_name_unique&quot;]

# Only Beers that Fit Our Criterion
dd.beers.2 &lt;- dd.beers[mean_overall &gt; 4.6 &amp; abv &lt; 10]

# Plot It!
ggplot(dd.beers.2, aes(x = abv, y = mean_overall, label = beer_name_unique, color = beer_name_unique)) +
  geom_point() +
  geom_text(aes(label=beer_name_unique),hjust=-.01, vjust=0) +
  labs(title = &quot;High Quality Beers with Low ABV&quot;,
       x = &quot;ABV&quot;,
       y = &quot;Mean Overall Rating&quot;) + theme(legend.position = &quot;none&quot;) +
  xlim(0, 20) +
  scale_y_continuous(breaks = c(seq(4.6,5,.1)), limits = c(4.6,4.85))</code></pre>
<p><img src="/post/2018-01-14-hire-me-as-a-data-scientist-part-ii_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>These are all OK choices (most of the beers are still above 5% ABV), but we do have one beer clocking in at 2.0% ABV giving us our final beer recommendation – the <a href="https://www.beeradvocate.com/beer/profile/1628/8626/">Southampton Publick House Southampton Berliner Weisse Berliner Weissbier</a>!</p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>After all of this I know have three beers to check out. <a href="https://www.beeradvocate.com/beer/profile/863/7971/">Pliny The Elder</a> is our winner for the top rated beer among our Super Users of the site, the <a href="https://www.beeradvocate.com/beer/profile/22511/67760/">Hill Farmstead Brewery Galaxy Imperial Single Hop IPA American Double / Imperial IPA</a> is a beer to maybe follow up on from our first choice, and then lastly we have the the <a href="https://www.beeradvocate.com/beer/profile/1628/8626/">Southampton Publick House Southampton Berliner Weisse Berliner Weissbier</a> which supposedly tastes great, despite its lack of alcohol content.</p>
</div>

    </div>
  </div>

</article>

<div class="container">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="/post/hire-me-as-a-data-scientist-part-i/"><span
      aria-hidden="true">&larr;</span> Hire Me (as a Data Scientist!), Part I</a></li>
    

    
  </ul>
</nav>

</div>

<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 David John Baker &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha512-jGsMH83oKe9asCpkOVkBnUrDDTp8wl+adkB2D+//JtlxO4SrLoJdhbOysIFQJloQFD+C4Fl1rMsQZF76JjV0eQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js" integrity="sha512-iHzEu7GbSc705hE2skyH6/AlTpOfBmkx7nUqTLGzPYR+C1tRaItbRlJ7hT/D3YQ9SV0fqLKzp4XY9wKulTBGTw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js" integrity="sha512-Z5heTz36xTemt1TbtbfXtTq5lMfYnOkXM2/eWcTTiLU01+Sw4ku1i7vScDc8fWhrP2abz9GQzgKH5NGBLoYlAw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/plugins/ScrollToPlugin.min.js" integrity="sha512-CDeU7pRtkPX6XJtF/gcFWlEwyaX7mcAp5sO3VIu/ylsdR74wEw4wmBpD5yYTrmMAiAboi9thyBUr1vXRPA7t0Q==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

