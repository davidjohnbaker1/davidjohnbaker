+++
# Date this page was created.
date = "2016-04-27"

# Project title.
title = "Computational Musicology"

# Project summary to display on homepage.
summary = "Computers, music, and data"

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "bach-kern.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["music-and-memory"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "bach-kern.png"
caption = " "

+++

Computational Musicology involves using computers to digitize musical data and then using powerful software to search through massive amounts of data that would be unfeasible to do by hand. I am particularly interested in using symbolic data to extract information from melodies that can be used to predict how well melodies are remembered and creating new data sets that others can use.

One project involving creating new datasets involves curating a dataset of improvised jazz solos.
In its current state, the corpus is encoded in **kern and has solos from Charlie Parker (~70), Clifford Brown (~80), as well as Dizzy Gillespie (~10).
We are in the process of including data from Miles Davis, John Coltrane, as well as other artists.
Though not publicly availible yet, the dataset will have both melodic as well as harmonic information and be easily indexed using the [Humdrum](http://www.humdrum.org/) tool kit.


